{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "date TEXT\n",
      "prcp FLOAT\n",
      "tobs FLOAT\n"
     ]
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "columns = inspector.get_columns('Measurement')\n",
    "for c in columns:\n",
    "    print(c['name'], c[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query/retrieve the last 12 months of precip data and plot the results:\n",
    "## First, Retrieve start and end dates for the period of last 12months: \n",
    "# session.query(func.count(Measurement.date)).all() # .first() \n",
    "## 19550 rows in Measurements ranging in dates 2010-01-01 to 2017-08-23\n",
    "## 2016 was a leap year, but 365 days in those last 12months, 2016-08 to 2017-08.\n",
    "## Capture last date, convert data type to use in timedelta function:\n",
    "last_day = session.query(Measurement.date).order_by(Measurement.date.desc()).first() \n",
    "last_day = str(last_day)\n",
    "last_date_s= (last_day[2:12]) \n",
    "last_date = dt.datetime.strptime(last_date_s, '%Y-%m-%d').date()\n",
    "# print(type(end_date))    ## <class 'datetime.datetime'>\n",
    "yr_ago = last_date - dt.timedelta(days=365) \n",
    "print(yr_ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query to retrieve the data and precipitation scores\n",
    "YrAgo = session.query(Measurement.station, Measurement.date, \\\n",
    "                      Measurement.prcp).\\\n",
    "                filter(Measurement.date > yr_ago).\\\n",
    "                order_by(Measurement.date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a Pandas DataFrame, set index to date column \n",
    "\n",
    "yrago_df = pd.DataFrame(YrAgo, columns=['station', 'date', 'precip'])\n",
    "yrago_df.set_index('date', inplace=True)\n",
    "yrago_df.head()\n",
    "# yrago_df.info()       # 2230 rows, 2021 precip values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by date --- AND GET RID OF NULL (NaN) VALUES ---\n",
    "yrago_df.sort_values('date', na_position='first')\n",
    "yrago_df['precip'].isnull().sum().sum()    ## 208 NaNv alues; ALL in precip column\n",
    "yrago_df.dropna(inplace=True)\n",
    "yrago_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrago_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "# yrago_df.info()  ## 2021 rows, precip = float\n",
    "yrago_df.describe()\n",
    "# yrago_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "locs = range(0, 2050, 25)\n",
    "labels = [\"2016/08\", \"2016/09\", \"2016/010\", \"2016/011\", \"2016/012\", \"2017/01\",\\\n",
    "          \"2017/02\", \"2017/03\", \"2017/04\", \"2017/05\", \"2017/06\", \"2017/07\",\\\n",
    "          \"2017/08\"]\n",
    "plt.xticks(locs, labels, rotation = 45)\n",
    "x = yrago_df.index\n",
    "y = yrago_df[\"precip\"]\n",
    "plt.xlim(0, 300)\n",
    "plt.bar(x, y, width=1.5)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Observation dates')\n",
    "plt.ylabel('Precipitation Score')\n",
    "plt.title('Daily Rainfall, per Hawaii weather stations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precipitation](Images/precipitation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Stations table\n",
    "columns = inspector.get_columns('Station')\n",
    "for c in columns:\n",
    "    print(c['name'], c[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "stations = session.query(Station.name).count()\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "StActive = yrago_df.groupby(['station']).size().to_frame('size').\\\n",
    "    reset_index().sort_values(['size'], ascending=[False])\n",
    "StActive     ## validation: total number of observations is 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_active = session.query(Measurement.station, func.count(Measurement.tobs)).\\\n",
    "    group_by(Measurement.station).order_by(func.count(Measurement.tobs).desc()).all()\n",
    "sta_active    ## validation: total observations = 19550, total rows in Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "active_min = session.query(func.min(Measurement.tobs)).\\\n",
    "    filter(Measurement.station == 'USC00519397').all()\n",
    "active_max = session.query(func.max(Measurement.tobs)).\\\n",
    "    filter(Measurement.station == 'USC00519397').all()\n",
    "active_avg = session.query(func.avg(Measurement.tobs)).\\\n",
    "    filter(Measurement.station == 'USC00519397').all()\n",
    "\n",
    "active_min, active_max, active_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station...\n",
    "active = session.query(Measurement.station, Measurement.date, Measurement.tobs).\\\n",
    "    filter(Measurement.station == 'USC00519397').all()\n",
    "active_sta = pd.DataFrame(active, columns=['station', 'date', 'temp'])\n",
    "active_sta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and plot the results as a histogram with bins = 12\n",
    "y = active_sta[\"temp\"]\n",
    "plt.xlim(58, 85)\n",
    "plt.hist(y, bins=12)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Temperatures')\n",
    "plt.ylabel('Numbers of times observed')\n",
    "plt.title('Daily Temperatures, per Hawaii weather stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function `calc_temps` will accept start date & end date, format '%Y-%m-%d' \n",
    "# and return min, avg, & max temperatures for that range of dates.\n",
    "def calc_temps(start_date, end_date):\n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), \\\n",
    "                         func.max(Measurement.tobs)).\\\n",
    "                    filter(Measurement.date >= start_date).\\\n",
    "                    filter(Measurement.date <= end_date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n",
    "start_date = '2016-09-14'\n",
    "end_date = '2016-09-29'\n",
    "templist = calc_temps(start_date, end_date)\n",
    "templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as Title, avg temp for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n",
    "x = 22\n",
    "y = templist[0][1]        ## y.info() shows y value as data type float\n",
    "yerror = np.array([[(y-templist[0][0]), (templist[0][2]-y)]]).T\n",
    "yerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x, y, width=15, edgecolor=\"black\")\n",
    "plt.errorbar(x, y, yerr=yerror, color=\"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Temp (F)')\n",
    "plt.title('Trip Avg Temp')\n",
    "plt.xlim(1, 45)\n",
    "plt.xlabel('Days of Trip, September')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total rainfall/ station for trip dates using the previous year for dates.\n",
    "# Sort in descending order by precipitation amount; list station, name, lat/long, elevation.\n",
    "start_date = '2016-09-14'\n",
    "end_date = '2016-09-29'\n",
    "join_trip = session.query(Measurement.station, Measurement.date, \\\n",
    "                          func.sum(Measurement.prcp), \\\n",
    "                          Station.latitude, Station.longitude, Station.elevation).\\\n",
    "            filter(Measurement.station == Station.station).\\\n",
    "            filter(Measurement.date >= start_date).\\\n",
    "            filter(Measurement.date <= end_date).\\\n",
    "            group_by(Measurement.station).\\\n",
    "            order_by(func.sum(Measurement.prcp).desc()).all()\n",
    "join_trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ********Testing Flask queries********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'2016-09-14': 14.280000000000001,\n",
       "  '2016-09-15': 4.96,\n",
       "  '2016-09-16': 0.8200000000000001,\n",
       "  '2016-09-17': 0.6799999999999999,\n",
       "  '2016-09-18': 0.53,\n",
       "  '2016-09-19': 0.32,\n",
       "  '2016-09-20': 1.03,\n",
       "  '2016-09-21': 1.17,\n",
       "  '2016-09-22': 1.44,\n",
       "  '2016-09-23': 1.57,\n",
       "  '2016-09-24': 0.28,\n",
       "  '2016-09-25': 0.09,\n",
       "  '2016-09-26': 1.67,\n",
       "  '2016-09-27': 1.3599999999999999,\n",
       "  '2016-09-28': 0.13,\n",
       "  '2016-09-29': 2.99}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_day = '2016-09-14'\n",
    "start_date = dt.datetime.strptime(start_day, '%Y-%m-%d').date()\n",
    "\n",
    "end_day = '2016-09-29'\n",
    "end_date = dt.datetime.strptime(end_day, '%Y-%m-%d').date()\n",
    "# print(type(start_date))   \n",
    "# print(start_date, end_date)\n",
    "\n",
    "num_days = (end_date - start_date).days\n",
    "# print(num_days)\n",
    "\n",
    "precip_trip = session.query(Measurement.date, func.sum(Measurement.prcp)).\\\n",
    "                            filter(Measurement.date >= start_day).\\\n",
    "                            filter(Measurement.date <= end_day).\\\n",
    "                            group_by(Measurement.date).\\\n",
    "                            order_by(Measurement.date).all()\n",
    "# print(type(precip_trip))  ## list\n",
    "# precip_trip\n",
    "precip_dict = dict(precip_trip)\n",
    "precip_dict\n",
    "precip = list(np.ravel(precip_dict, order='C'))\n",
    "precip\n",
    "# precip_days = precip[0:num_days+1]\n",
    "# precip_prcp = precip[num_days+1:-1]\n",
    "# print (f\"During your trip on {start_day} to {end_day} expect it to rain this much on each of {num_days} days:\")\n",
    "# print(precip_prcp)\n",
    "\n",
    "# precip_trip_dict = to_dict(precip_trip)\n",
    "# precip_trip_dict = precip_trip.json()\n",
    "# for row in precip_trip:\n",
    "                            \n",
    "#                             return [dict(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (AVGs for tmin, tmax, tavg for all data matching a month+day)\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \"\"\"\n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def mydaynorms(date):\n",
    "    join_trip = session.query(Measurement.station, Measurement.date, \\\n",
    "                          func.sum(Measurement.prcp), \\\n",
    "                          Station.latitude, Station.longitude, Station.elevation).\\\n",
    "            filter(Measurement.station == Station.station).\\\n",
    "            filter(Measurement.date >= start_date).\\\n",
    "            filter(Measurement.date <= end_date).\\\n",
    "            group_by(Measurement.station).\\\n",
    "            order_by(func.sum(Measurement.prcp).desc()).all()\n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
